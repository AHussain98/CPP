/* 
sharing state between multiple threads safely is hard. we need to protect data from data races.
concurrency makes it hard to debug programs as its hard to trace issues between threads

Threads created in the same process share the same virtual memory
Each thread has its own stack for for storing local variables and other data necessary for handling function calls

A thread local variable can be thought of as a global variable where each thread has its own copy.

Heap memory is shared by all threads

A data race happens when two threads are accessing the same memory at the same time and atleast one of the threads is modifying the data
This means the program in non-deterministic and must be avoided wherever possible

Two main options to avoid a data race: use an atomic data type or use a mutex

Immutable data structures can be accessed by multiple threads at once and should be prevalent

A common pattern is to always create new immutable objects instead of mutating
existing objects. When the new object is fully constructed and represents the
new state, it can be swapped with the old object. In that way, we can minimize
the critical sections of our code. Only the swap is a critical section, and hence
needs to be protected by an atomic operation or a mutex.

The state where the second thread is blocked by the first thread to finish its work is called contention.

When using mutex locks to protect shared resources, there is a risk of getting
stuck in a state called deadlock. A deadlock can happen when two threads are
waiting for each other to release their locks. None of the threads can proceed and
are stuck in a deadlock state. One condition that needs to be fulfilled for a
deadlock to occur is that one thread that already holds a lock tries to acquire an
additional lock.

We need to minimise the use of shared resources and utilise exclusive locking

Synchronous tasks are like the ordinary functions that we are used to in
a C++ program. When a synchronous task is finished doing whatever it is
supposed to do, it will return the control to the caller of the task. The caller of
the task is waiting or blocked until the synchronous task has finished.

An asynchronous task, on the other hand, will return the control back to the
caller immediately and instead perform its work concurrently.

When creating the thread, we pass in a callable object (a function, lambda, or a
functor) that the thread will begin to execute whenever it gets scheduled time on
the CPU. REMEMBER THAT THIS MEANS THREADS EXECUTE RIGHTAFTER CREATION

When a std::thread object is destructed, it must have been
joined or detached or it will cause the program to call std::terminate(), which by
default will call std::abort() if you haven't installed a custom std::terminate_handler.

Remember we have no control over the default scheduling of threads

join() is blocking, detach() is not

two threads could theoretically
use std::cout in parallel. Fortunately, std::cout is thread-safe and can be used from
multiple threads without introducing data races, so there is no undefined
behavior. However, it is still possible that the output generated by the threads are
interleaved

 It is possible to query a std::thread object
in what state it is by using the std::thread::joinable property. A thread is not
joinable if it has been:
Default constructed; that is, if it has nothing to execute
Moved from (its associated running thread has been transferred to another std::thread object)
Detached by a call to detach()
Already joined by a call to join()

Otherwise, the std::thread object is in the joinable state. Remember, when
a std::thread object is destructed, it must no longer be in the joinable state or the
program will terminate.


*/
